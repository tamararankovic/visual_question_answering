{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e5f5f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "27e22074",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "399d11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrenirani faster rcnn uz pomoc kog ce se izvlaciti regioni slika\n",
    "def get_faster_rcnn():\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(\n",
    "        pretrained=True, \n",
    "        pretrained_backbone=True, \n",
    "        trainable_backbone_layers=0)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "24fd6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images():\n",
    "    # TODO: DOBAVITI SVE SLIKE ::((\n",
    "    test_image_name = 'VizWiz_train_00000258.jpg'\n",
    "    image = PIL.Image.open(dir + test_image_name)\n",
    "    image = np.array(image)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    tensor = transform(image)\n",
    "    # prvi element uredjenog para je lista tenzora (transformisanih slika), dok je\n",
    "    # drugi element lista naziva tih slika\n",
    "    return ([tensor], [test_image_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e781859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions(images):\n",
    "    # images je uredjeni par, prvo su slike, a onda nazivi\n",
    "    image_titles = images[1]\n",
    "    images = images[0]\n",
    "    # mapa gde je kljuc naziv slike, a vrednost lista regiona, tako da je svaki region\n",
    "    # tenzor sa cetiri vrednosti (x1, x2, y1, y2) (?)\n",
    "    images_regions = {}\n",
    "    model = get_faster_rcnn()\n",
    "    predictions = model(images)\n",
    "    for imgindex, prediction in enumerate(predictions):\n",
    "        title = image_titles[imgindex]\n",
    "        images_regions[title] = []\n",
    "        boxes = prediction['boxes']\n",
    "        scores = prediction['scores']\n",
    "        for regindex, score in enumerate(scores):\n",
    "            # score se moze i menjati\n",
    "            if score > 0.45:\n",
    "                images_regions[title].append(boxes[regindex].detach().numpy())\n",
    "        print(title + ': ', len(images_regions[title]), ' regions')\n",
    "    return images_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e97927fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors(image_regions):\n",
    "    images_feature_vectors = {}\n",
    "    for title in image_regions.keys():\n",
    "        image_path = dir + title\n",
    "        image = PIL.Image.open(image_path)\n",
    "        feature_vectors = []\n",
    "        for region in image_regions[title]:\n",
    "            x1 = region[0]\n",
    "            y1 = region[1]\n",
    "            x2 = region[2]\n",
    "            y2 = region[3]\n",
    "            region_image = image.crop((x1, y1, x2, y2))\n",
    "            # oblik feature vektora - [1 1 1 .... 1 1] - duzine 512\n",
    "            feature_vectors.append(get_feature_vector(region_image))\n",
    "        images_feature_vectors[title] = feature_vectors\n",
    "    return images_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6f18b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(image):\n",
    "    model = models.resnet18(pretrained = True)\n",
    "    layer = model._modules.get('avgpool')\n",
    "    model.eval()\n",
    "    \n",
    "    scaler = transforms.Resize((224, 224))\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    \n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(image))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = None\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def my_hook(module_, input_, output_):\n",
    "        nonlocal my_embedding\n",
    "        my_embedding = output_\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(my_hook)\n",
    "    # 6. Run the model on our transformed image\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "    # 8. Return the feature vector\n",
    "    my_embedding = my_embedding.squeeze(2).squeeze(2).squeeze(0)\n",
    "    return my_embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d614af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VizWiz_train_00000258.jpg:  15  regions\n"
     ]
    }
   ],
   "source": [
    "images_feature_vectors = get_feature_vectors(get_regions(get_images()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40eb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
